## Hadoop 환경설정    

### netstat 설치

- 원활한 환경설정을 위해 프로세스와 포트번호를 확인할 수 있는 net-tools 설치

  ```sql
  sudo apt install net-tools
  ```



### hadoop 설치

- https://spidyweb.tistory.com/214

- Java

  ```sql
  # 패키지 업데이트 
  sudo apt update
  
  # 자바 설치 (11.0.14)
  sudo apt install ssh openjdk-8-jdk ant -y
  
  # ant -y 는 java 빌드 자동화 도구인 ant 설치도 yes 선택한 것 
  
  # 설치 확인
  java -version
  
  # openjdk version "11.0.14" 2022-01-18
  # OpenJDK Runtime Environment (build 11.0.14+9-Ubuntu-0ubuntu2.20.04)
  # OpenJDK 64-Bit Server VM (build 11.0.14+9-Ubuntu-0ubuntu2.20.04, mixed mode, sharing) 
  ```

- ssh 키 설정

  ```sql
  ssh-keygen -t rsa -P ""
  # ssh-keygen -p [-P old_passphrase] [-N new_passphrase] [-f keyfile] 
  # -t rsa : RSA 방식으로 암호화
  
  cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
  # 생성된 key 파일을 authorized_keys 에 추가 
  
  ssh localhost 
  # yes => 비밀번호 물어보지 않고 prompt 뜨면 생성 완료 확인
  ```

- hadoop 설치

  ```python
  wget <https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz>
  
  tar zxf hadoop-3.3.1.tar.gz
  ```

  - 환경변수 설정

    - **.bashrc**

      - 하둡 환경 변수 설정

      ```sql
      vi .bashrc
      ------------------------------------------------
      #Hadoop Related Options 
      export HADOOP_HOME=/home/hadoop/hadoop-3.3.1
      export HADOOP_INSTALL=$HADOOP_HOME 
      export HADOOP_MAPRED_HOME=$HADOOP_HOME
      export HADOOP_COMMON_HOME=$HADOOP_HOME
      export HADOOP_HDFS_HOME=$HADOOP_HOME
      export YARN_HOME=$HADOOP_HOME
      export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native 
      export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
      export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
      -------------------------------------------------
      
      source ~/.bashrc
      ```

    - **[hadoop-env.sh](http://hadoop-env.sh)**

      - yarn, HDFS, MapReduce 하둡관련된 프로젝트 셋팅에 관한 파일

      ```sql
      vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh
      
      ----------------
      #export JAVA_HOME=  부분의 #을 제거하고(주석제거)
      
      JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
      --------------------
      
      # java path 확인 
      which javac
      															# /usr/bin/javac
      readlink -f /usr/bin/javac 
      															# /usr/lib/jvm/java-8-openjdk-amd64/bin/javac
      ```

    - **core-site.xml**

      - HDFS와 Hadoop 핵심 property들을 정의하는 파일

      ```sql
      vi $HADOOP_HOME/etc/hadoop/core-site.xml
      
      ------------------
      <configuration>
      
      <property>
        <name>hadoop.tmp.dir</name>
        <value>/home/hadoop/tmpdata</value>
      </property>
      
      <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
      </property>
      
      </configuration>
      ----------------------
      
      mkdir tmpdata
      ```

    - **hdfs-site.xml**

      - 데이터 노드와 네임노드의 저장소 디렉토리를 설정하는 파일

      ```sql
      vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml 
      
      --------------
      <configuration>
      
      <property>
        <name>dfs.data.dir</name>
        <value>/home/hadoop/dfsdata/namenode</value>
      </property>
      
      <property>
        <name>dfs.data.dir</name>
        <value>/home/hadoop/dfsdata/datanode</value>
      </property>
      
      <property>
        <name>dfs.replication</name>
        <value>1</value>
      </property>
      
      </configuration>
      -----------------------
      ```

    - 스켈레톤 코드에선 건들지 않은 파일이지만 추가 설정함

      - **mapred-site.xml**

        - mapreduce 파일의 값을 정의하기 위한 파일

        ```sql
        vi $HADOOP_HOME/etc/hadoop/mapred-site.xml
        
        ----------------------
        <configuration>
        
        <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
        </property>
        
        </configuration>
        
        ----------------------
        ```

      - **yarn-site.xml**

        - YARN에 관련된 세팅들을 정의하는 파일
        - node manager, Resource manager, containers, application master 설정 포함

        ```sql
        vi $HADOOP_HOME/etc/hadoop/yarn-site.xml
        
        -------
        <configuration>
        
        <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
        </property>
        
        <property>
          <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>   
          <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        
        <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>0.0.0.0</value>
        </property>
        
        <property>
          <name>yarn.resourcemanager.address</name>
          <value>0.0.0.0:8032</value>
        </property>
        
        <property>
          <name>yarn.web-proxy.address</name>
          <value>0.0.0.0:8089</value>
        </property>
        
        <property>
          <name>yarn.acl.enable</name>
          <value>0</value>
        </property>
        
        <property>
          <name>yarn.nodemanager.env-whitelist</name> 
          <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PERPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
        </property>
        
        </configuration>
        ---------
        ```

  - (hdfs 처음 시작할 때만) Name Node Format

    ```sql
    hdfs namenode -format
    ```

- Hadoop 실행

  ```sql
  hadoop-3.3.1/sbin/start-dfs.sh
  hadoop-3.3.1/sbin/start-yarn.sh
  
  jps 
  
  #9569 NameNode
  #10133 ResourceManager
  #9944 SecondaryNameNode
  #10282 NodeManager
  #10714 WebAppProxyServer
  #10750 Jps
  #9743 DataNode
  ```

- WEb UI 확인    

  - hdfs : Name node - `http://localhost:9870`  Data node - `http://localhost:9864`
  - yarn : `http://localhost:8088`
  - spark : `http://localhost:8080` ⇒ 바꾼 포트 번호 `ex` `http://localhost:8081`



<hr> 



### zookeeper & kafka 설치

#### zookeeper

- 설치

  ```sql
  wget <http://apache.mirror.cdnetworks.com/zookeeper/stable/apache-zookeeper-3.6.3-bin.tar.gz>
  
  tar zxvf apache-zookeeper-3.6.3-bin.tar.gz
  ```

- 스냅샷, 트랙잭션 로그 등 저장할 폴더 생성

  ```sql
  cd apache-zookeeper-3.6.3-bin
  mkdir zookeeper_data
  ```

  - 서버가 여러대라면

    - 각 클러스터 노드마다 폴더 생성 후 id 값을 다르게 해서 저장

      `echo 1 > myid` (노드 1개면 이것만)

      `echo 2 > myid`

      - `cat myid` 로 확인가능

    - standalone 모드가 아니라면 호스트네임 지정 필요

      - ```
        vi /etc/hosts
        ```

        - `55.55.55.2    zookeeper01`

        - `55.55.55.4    zookeeper02`  ...

          - ip 주소값과 이름 사이엔 `tab`

          - zookeeper01 등의 이름이 각 node의 이름(=클러스터 내 node의 이름)

            ⇒ 구분만 되면 마음대로 명명해도 됨

- 설정 파일 수정

  ```sql
  cd /home/hadoop/apache-zookeeper-3.6.3-bin/conf
  
  # 템플릿 복사
  cp zoo_sample.cfg zoo.cfg
  
  vi zoo.cfg
  ----
  dataDir=/home/hadoop/apache-zookeeper-3.6.3-bin/zookeeper_data
  ------
  ```

  - 서버가 여러대라면

    - 위에서 호스트네임 설정했다면, cfg 파일 내부에 아래 코드 추가 작성

      - 클러스터 노드 수에 따라 작성 (아래 코드는 2개인 상태)

      ```sql
      server.1=zookeeper01:2888:3888
      server.2=zookeeper02:2888:3888
      ```

- 실행

  ```sql
  cd /home/hadoop/apache-zookeeper-3.6.3-bin/bin
  
  ./zkServer.sh start 
  
  jps
  # QuorumPeerMain 실행 확인
  ```



#### kafka

- 설치

  ```sql
  wget <https://dlcdn.apache.org/kafka/3.1.0/kafka_2.13-3.1.0.tgz>
  
  tar zxvf kafka_2.13-3.1.0.tgz
  ```

- 분산 저장 디렉토리 생성

  ```sql
  cd kafka_2.13-3.1.0
  
  mkdir data
  # 파티션 2개 만들고 싶다면 data1, data2 생성
  ```

- 설정 파일 수정

  ```sql
  cd config
  
  vi server.properties
  ------
  ############################# Server Basics #############################
  broker.id=1
  
  ############################# Log Basics #############################
  log.dirs=/home/hadoop/kafka_2.13-3.1.0/data
  // 만약 data1, data2를 만들었다면, {kafka 경로}/data1, {kafka 경로}/data2
  ...(중략)...
  
  ############################# Zookeeper #############################
  zookeeper.connect=localhost:2181/localhost
  ```

- 실행

  ```sql
  # jps 로 zookeeper 실행중인지 확인!!!
  
  bin/kafka-server-start.sh config/server.properties
  ```

- kafka 기본 명령어

  `cd kafka_2.13-3.1.0/bin`

  - topic 리스트 확인

    - `./kafka-topics.sh --list --bootstrap-server localhost:9092`

  - topic 생성

    - ```
      ./kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic {Topic name}
      ```

      - replication factor : 복제본의 갯수, 기본 값은 3으로 하나의 파티션이 총 3개로 분산 저장되는 것이다.
      - —create : 토픽 생성을 하겟다
      - —bootstrap-server : 토픽 생성을 위해 붙을 브로커 주소
      - —partitions : 토픽의 파티션 개수
      - —topic : 생성할 토픽의 이름

  - topic producer

    - `./kafka-console-producer.sh --broker-list localhost:9092 --topic {보내고 싶은 Topic name}`

  - topic consumer

    - `./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic {보고 싶은 Topic name} --from-beginning`   



<hr> 



### spark 설치

- 설치

  ```sql
  wget <https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz>
  # 스파크 3.1.2 버전 압축 파일 다운로드
  
  tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz
  # 압축 풀기
  
  cp -r spark-3.1.2-bin-hadoop3.2 /home/hadoop/spark-3.1.2
  # 압축 푼 폴더를 복사하고, 폴더명을 spark-3.1.2-bin-hadoop3.2 에서 spark-3.1.2로 변경
  ```

- .bashrc 설정 변경

  ```sql
  export SPARK_HOME=/home/hadoop/spark-3.1.2
  export PATH="$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH"
  -----
  source .bashrc
  ```

- 설치 확인

  ```sql
  spark-submit --version
  
  # Welcome to Spark 나오면 성공
  
  # 참고 : spark-submit --help
  ```

- 환경 설정

  ```sql
  cd spark-3.1.2/conf
  
  # 템플릿 복사
  cp [spark-env.sh](<http://spark-env.sh>).template [spark-env.sh](<http://spark-env.sh/>)
  
  vi spark-env.sh
  
  # worker 인스턴스 수정하는 부분인데, 단일이면 pass
  ------
  # - MESOS_NATIVE_JAVA_LIBRARY, to point to your libmesos.so if you use Mesos
  export SPARK_WORKER_INSTANCES=2
  # Options read in YARN client/cluster mode
  -------
  
  # zookeepr 와 port 충돌을 막기 위해 port 지정 
  ------
  SPARK_MASTER_WEBUI_PORT=8081
  -------
  ```

- 실행

  ```sql
  # hadoop(dfs, yarn) 실행된 상태여야함!!!!
  # Jps, NodeManager, ResourceManager, NameNode, DataNode 5개는 떠야함
  
  cd /home/hadoop/spark-3.1.2/sbin
  
  # master-job 실행
  start-master.sh
  
  # worker job 실행
  start-slave.sh spark://ubuntu:7077
  
  # 뒷 부분 주소는 master 실행 후, localhost:8081 에서 확인 가능
  # worker 수는 환경설정에서 정한 수 대로 실행됨 (Default=1)
  ```



- 테스트 (작업을 master 위치에 올리기)

  ```sql
  cd /home/hadoop/spark-3.1.2/bin
  spark-shell --master spark://ubuntu:7077
  
  -----code (scalar)
  val lines = sc.textFile("./spark-3.1.2/README.md")
  lines.count()
  ------
  
  # localhost:8081 에서 running application 확인 시 실행 확인 가능 
  # spark 종료 시 completed application 에 종료확인 가능
  ```



<hr> 

